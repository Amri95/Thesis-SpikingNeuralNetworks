{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import nengo\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nengo_dl\n",
    "\n",
    "# keras uses the global random seeds, so we set those here to\n",
    "# ensure the example is reproducible\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "with nengo.Network(seed=0) as net:\n",
    "    # set up some default parameters to match the Keras defaults\n",
    "    net.config[nengo.Ensemble].gain = nengo.dists.Choice([1])\n",
    "    net.config[nengo.Ensemble].bias = nengo.dists.Choice([0])\n",
    "    net.config[nengo.Connection].synapse = None\n",
    "    net.config[nengo.Connection].transform = nengo_dl.dists.Glorot()\n",
    "\n",
    "    # input node, same as before\n",
    "    inp = nengo.Node(output=np.ones(X.shape[1]))\n",
    "\n",
    "    # add the first dense layer\n",
    "    hidden = nengo.Ensemble(64, 1, neuron_type=nengo.RectifiedLinear()).neurons\n",
    "    nengo.Connection(inp, hidden)\n",
    "    hidden2 = nengo.Ensemble(64, 1, neuron_type=nengo.RectifiedLinear()).neurons\n",
    "    nengo.Connection(hidden, hidden2)\n",
    "\n",
    "    # add the linear output layer (using nengo.Node since there is\n",
    "    # no nonlinearity)\n",
    "    out = nengo.Node(size_in=len(set(y)))\n",
    "    nengo.Connection(hidden2, out)\n",
    "\n",
    "    # add a probe to collect output\n",
    "    out_p = nengo.Probe(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = X[:, None, :]\n",
    "y = y[:, None, None]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build finished in 0:00:00                                                      \n",
      "Optimization finished in 0:00:00                                               \n",
      "Train on 120 samples\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 0s 1ms/sample - loss: 1.0647 - probe_loss: 1.0647 - probe_accuracy: 0.5417\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 0s 542us/sample - loss: 0.7094 - probe_loss: 0.7094 - probe_accuracy: 0.7583\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 0s 558us/sample - loss: 0.5370 - probe_loss: 0.5370 - probe_accuracy: 0.7500\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 0s 550us/sample - loss: 0.4409 - probe_loss: 0.4409 - probe_accuracy: 0.8500\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 0s 558us/sample - loss: 0.4023 - probe_loss: 0.4023 - probe_accuracy: 0.8583\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 0s 567us/sample - loss: 0.3472 - probe_loss: 0.3472 - probe_accuracy: 0.9333\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 0s 617us/sample - loss: 0.3197 - probe_loss: 0.3197 - probe_accuracy: 0.9333\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 0s 575us/sample - loss: 0.2854 - probe_loss: 0.2854 - probe_accuracy: 0.9500\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 0s 592us/sample - loss: 0.2583 - probe_loss: 0.2583 - probe_accuracy: 0.9417\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 0s 583us/sample - loss: 0.2363 - probe_loss: 0.2363 - probe_accuracy: 0.9667\n",
      "Test accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "with net:\n",
    "    nengo_dl.configure_settings(stateful=False, use_loop=False)\n",
    "\n",
    "with nengo_dl.Simulator(net, minibatch_size=6) as sim:\n",
    "    sim.compile(optimizer=tf.optimizers.Adam(),\n",
    "                loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=[\"accuracy\"])\n",
    "    sim.fit(X_train, y_train, epochs=10)\n",
    "\n",
    "    print(\"Test accuracy:\", sim.evaluate(\n",
    "        X_test, y_test, verbose=0)[\"probe_accuracy\"])\n",
    "    \n",
    "    sim.save_params(\"./iris_snn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build finished in 0:00:00                                                      \n",
      "Optimization finished in 0:00:00                                               \n",
      "Test loss:  0.2565461978316307\n",
      "Test accuracy:  0.9\n",
      "Test F1 Score:  0.9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "with nengo_dl.Simulator(net, minibatch_size=6) as sim2:\n",
    "    sim2.load_params(\"./iris_snn\")\n",
    "    predictions = sim2.predict(X_test)[out_p]\n",
    "    y_pred = []\n",
    "    for p in predictions:\n",
    "        y_pred.append(np.argmax(p[0]))\n",
    "    sim2.compile(optimizer=tf.optimizers.Adam(),\n",
    "            loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            metrics=[\"accuracy\"])\n",
    "    print(\"Test loss: \", sim2.evaluate(X_test, y_test, verbose=0)['loss'])\n",
    "    print(\"Test accuracy: \", accuracy_score(y_test.flatten(), y_pred))\n",
    "    print(\"Test F1 Score: \", f1_score(y_test.flatten(), y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "with nengo.Network(seed=seed) as net:\n",
    "    # input node, same as before\n",
    "    inp = nengo.Node(output=np.ones(X.shape[1]))\n",
    "\n",
    "    # add the Dense layers, as in the Keras model\n",
    "    hidden = nengo_dl.Layer(\n",
    "        tf.keras.layers.Dense(units=64, activation=tf.nn.relu))(inp)\n",
    "    hidden2 = nengo_dl.Layer(\n",
    "        tf.keras.layers.Dense(units=64, activation=tf.nn.relu))(hidden)\n",
    "    out = nengo_dl.Layer(\n",
    "        tf.keras.layers.Dense(units=len(set(y))))(hidden2)\n",
    "\n",
    "    # add a probe to collect output\n",
    "    out_p = nengo.Probe(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 1, 4)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 1, 1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build finished in 0:00:00                                                      \n",
      "Optimization finished in 0:00:00                                               \n",
      "Train on 120 samples\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 0s 933us/sample - loss: 1.0128 - probe_loss: 1.0128 - probe_accuracy: 0.5750\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 0s 450us/sample - loss: 0.8427 - probe_loss: 0.8427 - probe_accuracy: 0.6583\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 0s 433us/sample - loss: 0.6728 - probe_loss: 0.6728 - probe_accuracy: 0.7250\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 0s 458us/sample - loss: 0.5555 - probe_loss: 0.5555 - probe_accuracy: 0.7750\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 0s 433us/sample - loss: 0.4800 - probe_loss: 0.4800 - probe_accuracy: 0.8667\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 0s 425us/sample - loss: 0.4119 - probe_loss: 0.4119 - probe_accuracy: 0.9083\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 0s 433us/sample - loss: 0.3704 - probe_loss: 0.3704 - probe_accuracy: 0.8833\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 0s 442us/sample - loss: 0.3351 - probe_loss: 0.3351 - probe_accuracy: 0.9417\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 0s 425us/sample - loss: 0.3085 - probe_loss: 0.3085 - probe_accuracy: 0.9083\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 0s 508us/sample - loss: 0.2883 - probe_loss: 0.2883 - probe_accuracy: 0.9333\n",
      "Test accuracy: 0.93333334\n"
     ]
    }
   ],
   "source": [
    "with net:\n",
    "    nengo_dl.configure_settings(stateful=False, use_loop=False)\n",
    "\n",
    "with nengo_dl.Simulator(net, minibatch_size=6) as sim:\n",
    "    sim.compile(optimizer=tf.optimizers.Adam(),\n",
    "                loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=[\"accuracy\"])\n",
    "    sim.fit(X_train, y_train, epochs=10)\n",
    "\n",
    "    print(\"Test accuracy:\", sim.evaluate(\n",
    "        X_test, y_test, verbose=0)[\"probe_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build finished in 0:00:00                                                      \n",
      "Optimization finished in 0:00:00                                               \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 0.3828    , -0.10269964,  0.1600502 ], dtype=float32),\n",
       " array([ 0.4032839 , -0.16633818,  0.38782042], dtype=float32),\n",
       " array([ 0.10945285, -0.00089379,  0.07321441], dtype=float32),\n",
       " array([ 0.49845922, -0.09372929,  0.3818662 ], dtype=float32),\n",
       " array([ 0.13050717, -0.02711663,  0.11718857], dtype=float32),\n",
       " array([ 0.4298821 , -0.01159807,  0.10131407], dtype=float32),\n",
       " array([ 0.12207904, -0.05359422,  0.12546197], dtype=float32),\n",
       " array([ 0.41004848, -0.09425357,  0.25363475], dtype=float32),\n",
       " array([ 0.4382305 , -0.13365176,  0.34510392], dtype=float32),\n",
       " array([ 0.3618262 , -0.11051926,  0.24229154], dtype=float32),\n",
       " array([ 0.41096488, -0.01255447,  0.28590828], dtype=float32),\n",
       " array([ 0.3774116 , -0.05764061,  0.17933172], dtype=float32),\n",
       " array([ 0.39414456, -0.01771963,  0.22566038], dtype=float32),\n",
       " array([ 0.41148368, -0.13054562,  0.29951066], dtype=float32),\n",
       " array([ 0.39243472, -0.02714005,  0.20145038], dtype=float32),\n",
       " array([0.10534459, 0.01297808, 0.06673008], dtype=float32),\n",
       " array([ 0.37564304, -0.05286121,  0.18981767], dtype=float32),\n",
       " array([ 0.35853025, -0.00303786,  0.1843257 ], dtype=float32),\n",
       " array([ 0.14509523, -0.07383072,  0.16642773], dtype=float32),\n",
       " array([ 0.12542684, -0.06751904,  0.12691134], dtype=float32),\n",
       " array([ 0.3730867 , -0.04388976,  0.13118443], dtype=float32),\n",
       " array([0.34620282, 0.01643929, 0.0855251 ], dtype=float32),\n",
       " array([0.12920481, 0.07121575, 0.00159457], dtype=float32),\n",
       " array([ 0.12430489, -0.02535938,  0.10949671], dtype=float32),\n",
       " array([ 0.40149486, -0.10528223,  0.24231966], dtype=float32),\n",
       " array([ 0.08659931, -0.01255058,  0.07354099], dtype=float32),\n",
       " array([ 0.12730795,  0.05290502, -0.01625767], dtype=float32),\n",
       " array([ 0.37549457, -0.07338518,  0.226679  ], dtype=float32),\n",
       " array([ 0.2982585 , -0.07636006,  0.19594604], dtype=float32),\n",
       " array([ 0.13802984, -0.02710365,  0.09784549], dtype=float32)]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with nengo_dl.Simulator(net, minibatch_size=6) as sim:\n",
    "    predictions = sim.predict(X_test)[out_p]\n",
    "    y_pred = []\n",
    "    for p in predictions:\n",
    "        y_pred.append(p[0])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
